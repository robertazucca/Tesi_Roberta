{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import datetime, date\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\"03-05-21\", \"10-05-21\", \"17-05-21\", \"24-05-21\", \"31-05-21\", \"07-06-21\", \"14-06-21\", \"21-06-21\", \"28-06-21\", \"05-07-21\", \"12-07-21\", \"19-07-21\", \"26-07-21\", \"02-08-21\", \"09-08-21\",\n",
    "\"16-08-21\", \"23-08-21\", \"30-08-21\", \"06-09-21\"]\n",
    "chan_dir = 'channels/'\n",
    "nod_dir = 'nodes/'\n",
    "historic_filenames = ['datasetLun/ln_' + str(date) + '.json' for date in dates]\n",
    "channels_dir = ['datasetLun/ln_' + str(date) + '.json__edges.json' for date in dates]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ogni dataset lo divido in file dei canali e file dei nodi per passarli per la costruzione dei grafi\n",
    "for filename in historic_filenames:\n",
    "    with open(filename,'r', encoding='utf-8') as data_file:    \n",
    "        data_channels = json.load(data_file)\n",
    "    df_channels = pd.json_normalize(data_channels,record_path = [\"edges\"])\n",
    "    #display(df_channels)\n",
    "\n",
    "    to_write_n = df_channels.to_json(orient='records', indent = 1)\n",
    "    with open (filename + '__edges.json', \"w\") as file:\n",
    "        file.write(to_write_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in historic_filenames:\n",
    "    with open (filename,'r', encoding='utf-8') as data_file:\n",
    "        data_nodes = json.load(data_file)\n",
    "    df_nodes = pd.json_normalize(data_nodes, record_path=[\"nodes\"])\n",
    "#tengo solo le prime 5 colonne\n",
    "    df_drop_n = df_nodes.drop(df_nodes.iloc[:,5:68],axis=1)\n",
    "\n",
    "    to_write_n = df_drop_n.to_json(orient='records', indent = 1)\n",
    "    with open (filename + '__nodes.json', \"w\") as file:\n",
    "        file.write(to_write_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divido i dataset relativi ai mesi di aprile e meggio -> quelli che hanno pi√π dati\n",
    "\n",
    "dates_new = [\"23-04-21\", \"24-04-21\", \"25-04-21\", \"26-04-21\", \"27-04-21\", \"28-04-21\", \"29-04-21\", \"30-04-21\", \"01-05-21\", \"02-05-21\", \"03-05-21\", \"04-05-21\", \"05-05-21\", \"06-05-21\", \"07-05-21\",\n",
    "\"08-05-21\", \"09-05-21\", \"10-05-21\"]\n",
    "\n",
    "dir_dataset = ['datasetAprileMaggio/ln_' + str(date) + '.json' for date in dates_new]\n",
    "dir_channels = ['datasetAprileMaggio/ln_' + str(date) + '.json__edges.json' for date in dates_new]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ogni dataset lo divido in file dei canali e file dei nodi per passarli per la costruzione dei grafi\n",
    "for filename in dir_dataset:\n",
    "    with open(filename,'r', encoding='utf-8') as data_file:    \n",
    "        data_channels = json.load(data_file)\n",
    "    df_channels = pd.json_normalize(data_channels,record_path = [\"edges\"])\n",
    "    #display(df_channels)\n",
    "\n",
    "    to_write_n = df_channels.to_json(orient='records', indent = 1)\n",
    "    with open (filename + '__edges.json', \"w\") as file:\n",
    "        file.write(to_write_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in dir_dataset:\n",
    "    with open (filename,'r', encoding='utf-8') as data_file:\n",
    "        data_nodes = json.load(data_file)\n",
    "    df_nodes = pd.json_normalize(data_nodes, record_path=[\"nodes\"])\n",
    "#tengo solo le prime 5 colonne\n",
    "    df_drop_n = df_nodes.drop(df_nodes.iloc[:,5:68],axis=1)\n",
    "\n",
    "    to_write_n = df_drop_n.to_json(orient='records', indent = 1)\n",
    "    with open (filename + '__nodes.json', \"w\") as file:\n",
    "        file.write(to_write_n)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90e315135b2281b752a7f250632c791a0dae1003299eabe9b8abad9d58b3e8e7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
