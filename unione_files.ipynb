{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import operator\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from  operator import itemgetter\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_new = [\"23-04-21\", \"24-04-21\", \"25-04-21\", \"26-04-21\", \"27-04-21\", \"28-04-21\", \"29-04-21\", \"30-04-21\", \"01-05-21\", \"02-05-21\", \"03-05-21\", \"04-05-21\", \"05-05-21\", \"06-05-21\", \"07-05-21\",\n",
    "\"08-05-21\", \"09-05-21\", \"10-05-21\"]\n",
    "week_1_dates = [\"23-04-21\", \"24-04-21\", \"25-04-21\"] \n",
    "week_2_dates = [\"26-04-21\", \"27-04-21\", \"28-04-21\", \"29-04-21\", \"30-04-21\", \"01-05-21\", \"02-05-21\"]\n",
    "week_3_dates = [\"03-05-21\", \"04-05-21\", \"05-05-21\", \"06-05-21\", \"07-05-21\", \"08-05-21\", \"09-05-21\"]\n",
    "week_4_dates = [\"10-05-21\"]\n",
    "\n",
    "\n",
    "dir_dataset = 'datasetAprileMaggio/'\n",
    "files_dataset1 = ['ln_' + str(date) + '.json' for date in week_1_dates]\n",
    "files_dataset2 = ['ln_' + str(date) + '.json' for date in week_2_dates]\n",
    "files_dataset3 = ['ln_' + str(date) + '.json' for date in week_3_dates]\n",
    "\n",
    "dir_channels = 'datasetAprileMaggio/channels/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19482"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "43380"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di canali nel file unione: 19482\n",
      "In comune tra il giorno corrente e il file unione: 19390\n",
      "DF_CHANNELS LEN: 43380\n",
      "Numero di canali diversi nel nuovo file: 23990\n",
      "Numero di canali totali dopo questa iterazione 43472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43554"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di canali nel file unione: 43472\n",
      "In comune tra il giorno corrente e il file unione: 43243\n",
      "DF_CHANNELS LEN: 43554\n",
      "Numero di canali diversi nel nuovo file: 311\n",
      "Numero di canali totali dopo questa iterazione 43783\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for filename in files_dataset1:\n",
    "\n",
    "    with open (dir_channels+'channels_' + filename) as data_file:    \n",
    "        data_channels = json.load(data_file)\n",
    "    df_channels = pd.json_normalize(data_channels)\n",
    "    display(len(df_channels))\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    if i == 1:\n",
    "        \n",
    "        #il file non esiste, quindi sto considerando il primo giorno e devo solo inserire nel file unione tutti i canali del primo file\n",
    "        df_allchannels = df_channels\n",
    "        display(df_channels.equals(df_allchannels))\n",
    "    \n",
    "    else:\n",
    "        #il file esiste, devo aggiungere i canali che ancora non ho     \n",
    "        print(\"Numero di canali nel file unione:\", len(df_allchannels))\n",
    "\n",
    "        #prendo i canali del nuovo dataset che sono anche nel file unione\n",
    "        in_common = df_channels[df_channels['channel_id'].isin(df_allchannels['channel_id'])]\n",
    "        print(\"In comune tra il giorno corrente e il file unione:\" ,len(in_common))\n",
    "\n",
    "\n",
    "        #a questo punto devo prendere i canali aperti del file del giorno, che non si trovano nel grande file, ed aggiungerli\n",
    "        df_diff_channels = df_channels[~df_channels['channel_id'].isin(df_allchannels['channel_id'])]\n",
    "        print(\"Numero di canali diversi nel nuovo file:\", len(df_diff_channels))\n",
    "\n",
    "        #creo il nuovo file mettendo insieme tutti i vecchi + quelli nuovi che ancora non erano nel file unione\n",
    "        new_df = pd.concat([df_allchannels, df_diff_channels])\n",
    "        print(\"Numero di canali totali dopo questa iterazione\", len(new_df))\n",
    "\n",
    "        df_allchannels = new_df\n",
    "\n",
    "#memorizzo su file in formato json\n",
    "to_write = df_allchannels.to_json(orient='records', indent = 1)\n",
    "with open(dir_dataset + 'unione_channels/'+ 'week1.json', \"w\") as f:\n",
    "    f.write(to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF_CHANNELS LEN: 43672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF_CHANNELS LEN: 43647\n",
      "Numero di canali nel file unione: 43672\n",
      "In comune tra il giorno corrente e il file unione: 43496\n",
      "DF_CHANNELS LEN: 43647\n",
      "Numero di canali diversi nel nuovo file: 151\n",
      "Numero di canali totali dopo questa iterazione 43823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF_CHANNELS LEN: 43465\n",
      "Numero di canali nel file unione: 43823\n",
      "In comune tra il giorno corrente e il file unione: 43465\n",
      "DF_CHANNELS LEN: 43465\n",
      "Numero di canali diversi nel nuovo file: 0\n",
      "Numero di canali totali dopo questa iterazione 43823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF_CHANNELS LEN: 43331\n",
      "Numero di canali nel file unione: 43823\n",
      "In comune tra il giorno corrente e il file unione: 43331\n",
      "DF_CHANNELS LEN: 43331\n",
      "Numero di canali diversi nel nuovo file: 0\n",
      "Numero di canali totali dopo questa iterazione 43823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF_CHANNELS LEN: 43163\n",
      "Numero di canali nel file unione: 43823\n",
      "In comune tra il giorno corrente e il file unione: 43163\n",
      "DF_CHANNELS LEN: 43163\n",
      "Numero di canali diversi nel nuovo file: 0\n",
      "Numero di canali totali dopo questa iterazione 43823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF_CHANNELS LEN: 42974\n",
      "Numero di canali nel file unione: 43823\n",
      "In comune tra il giorno corrente e il file unione: 42974\n",
      "DF_CHANNELS LEN: 42974\n",
      "Numero di canali diversi nel nuovo file: 0\n",
      "Numero di canali totali dopo questa iterazione 43823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF_CHANNELS LEN: 42778\n",
      "Numero di canali nel file unione: 43823\n",
      "In comune tra il giorno corrente e il file unione: 42778\n",
      "DF_CHANNELS LEN: 42778\n",
      "Numero di canali diversi nel nuovo file: 0\n",
      "Numero di canali totali dopo questa iterazione 43823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "for filename in files_dataset2:\n",
    "\n",
    "    with open (dir_channels+'channels_' + filename) as data_file:    \n",
    "        data_channels = json.load(data_file)\n",
    "    df_channels = pd.json_normalize(data_channels)\n",
    "    print(\"DF_CHANNELS LEN:\" ,len(df_channels))\n",
    "\n",
    "    i+=1\n",
    "\n",
    "    if i == 1:\n",
    "        \n",
    "        #il file non esiste, quindi sto considerando il primo giorno e devo solo inserire nel file unione tutti i canali del primo file\n",
    "        df_allchannels = df_channels\n",
    "        display(i)\n",
    "        #display(df_allchannels)\n",
    "    \n",
    "    else:\n",
    "        #il file esiste, devo aggiungere i canali che ancora non ho     \n",
    "        print(\"Numero di canali nel file unione:\", len(df_allchannels))\n",
    "\n",
    "        #prendo i canali del nuovo dataset che sono anche nel file unione\n",
    "        in_common = df_channels[df_channels[\"channel_id\"].isin(df_allchannels[\"channel_id\"])]\n",
    "        print(\"In comune tra il giorno corrente e il file unione:\" ,len(in_common))\n",
    "        print(\"DF_CHANNELS LEN:\" ,len(df_channels))\n",
    "\n",
    "\n",
    "        #a questo punto devo prendere i canali aperti del file del giorno, che non si trovano nel grande file, ed aggiungerli\n",
    "        df_channels_copy = df_channels.copy()\n",
    "        df_diff_channels = df_channels_copy[~df_channels_copy['channel_id'].isin(df_allchannels[\"channel_id\"])]\n",
    "        print(\"Numero di canali diversi nel nuovo file:\", len(df_diff_channels))\n",
    "\n",
    "        #creo il nuovo file mettendo insieme tutti i vecchi + quelli nuovi che ancora non erano nel file unione\n",
    "        new_df = pd.concat([df_allchannels, df_diff_channels])\n",
    "        print(\"Numero di canali totali dopo questa iterazione\", len(new_df))\n",
    "\n",
    "        display(i)\n",
    "        df_allchannels = new_df\n",
    "\n",
    "#memorizzo su file in formato json\n",
    "to_write = df_allchannels.to_json(orient='records', indent = 1)\n",
    "with open(dir_dataset + 'unione_channels/'+ 'week1.json', \"w\") as f:\n",
    "    f.write(to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF_CHANNELS LEN: 42563\n",
      "DF_CHANNELS LEN: 42255\n",
      "Numero di canali nel file unione: 42563\n",
      "In comune tra il giorno corrente e il file unione: 42255\n",
      "DF_CHANNELS LEN: 42255\n",
      "Numero di canali diversi nel nuovo file: 0\n",
      "Numero di canali totali dopo questa iterazione 42563\n",
      "DF_CHANNELS LEN: 41986\n",
      "Numero di canali nel file unione: 42563\n",
      "In comune tra il giorno corrente e il file unione: 41986\n",
      "DF_CHANNELS LEN: 41986\n",
      "Numero di canali diversi nel nuovo file: 0\n",
      "Numero di canali totali dopo questa iterazione 42563\n",
      "DF_CHANNELS LEN: 41697\n",
      "Numero di canali nel file unione: 42563\n",
      "In comune tra il giorno corrente e il file unione: 41697\n",
      "DF_CHANNELS LEN: 41697\n",
      "Numero di canali diversi nel nuovo file: 0\n",
      "Numero di canali totali dopo questa iterazione 42563\n",
      "DF_CHANNELS LEN: 41503\n",
      "Numero di canali nel file unione: 42563\n",
      "In comune tra il giorno corrente e il file unione: 41503\n",
      "DF_CHANNELS LEN: 41503\n",
      "Numero di canali diversi nel nuovo file: 0\n",
      "Numero di canali totali dopo questa iterazione 42563\n",
      "DF_CHANNELS LEN: 41226\n",
      "Numero di canali nel file unione: 42563\n",
      "In comune tra il giorno corrente e il file unione: 41226\n",
      "DF_CHANNELS LEN: 41226\n",
      "Numero di canali diversi nel nuovo file: 0\n",
      "Numero di canali totali dopo questa iterazione 42563\n",
      "DF_CHANNELS LEN: 40976\n",
      "Numero di canali nel file unione: 42563\n",
      "In comune tra il giorno corrente e il file unione: 40976\n",
      "DF_CHANNELS LEN: 40976\n",
      "Numero di canali diversi nel nuovo file: 0\n",
      "Numero di canali totali dopo questa iterazione 42563\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for filename in files_dataset3:\n",
    "\n",
    "    with open (dir_channels+'channels_' + filename) as data_file:    \n",
    "        data_channels = json.load(data_file)\n",
    "    df_channels = pd.json_normalize(data_channels)\n",
    "    print(\"DF_CHANNELS LEN:\" ,len(df_channels))\n",
    "    i+=1\n",
    "\n",
    "    if i == 1:\n",
    "        \n",
    "        #il file non esiste, quindi sto considerando il primo giorno e devo solo inserire nel file unione tutti i canali del primo file\n",
    "        df_allchannels = df_channels\n",
    "    \n",
    "    else:\n",
    "        #il file esiste, devo aggiungere i canali che ancora non ho     \n",
    "        print(\"Numero di canali nel file unione:\", len(df_allchannels))\n",
    "\n",
    "        #prendo i canali del nuovo dataset che sono anche nel file unione\n",
    "        in_common = df_channels[df_channels['channel_id'].isin(df_allchannels['channel_id'])]\n",
    "        print(\"In comune tra il giorno corrente e il file unione:\" ,len(in_common))\n",
    "        print(\"DF_CHANNELS LEN:\" ,len(df_channels))\n",
    "\n",
    "\n",
    "        #a questo punto devo prendere i canali aperti del file del giorno, che non si trovano nel grande file, ed aggiungerli\n",
    "        df_diff_channels = df_channels[~df_channels['channel_id'].isin(in_common['channel_id'])]\n",
    "        print(\"Numero di canali diversi nel nuovo file:\", len(df_diff_channels))\n",
    "\n",
    "        #creo il nuovo file mettendo insieme tutti i vecchi + quelli nuovi che ancora non erano nel file unione\n",
    "        new_df_already_taken = pd.concat([df_allchannels, df_diff_channels])\n",
    "        print(\"Numero di canali totali dopo questa iterazione\", len(new_df_already_taken))\n",
    "\n",
    "        df_allchannels = new_df_already_taken\n",
    "\n",
    "#memorizzo su file in formato json\n",
    "to_write = df_allchannels.to_json(orient='records', indent = 1)\n",
    "with open(dir_dataset + 'unione_channels/'+ 'week3.json', \"w\") as f:\n",
    "    f.write(to_write)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "042a03a709baefc4696b89b1773a1551f77cb3b721a024643b48fc758e4895f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
