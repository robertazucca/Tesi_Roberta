{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import operator\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from  operator import itemgetter\n",
    "from scipy.stats import norm\n",
    "import seaborn as sb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_1_dates = [\"11-05-21\", \"12-05-21\", \"13-05-21\", \"14-05-21\", \"15-05-21\", \"16-05-21\"] \n",
    "week_2_dates = [\"17-05-21\", \"18-05-21\", \"19-05-21\", \"20-05-21\", \"21-05-21\", \"22-05-21\", \"23-05-21\"]\n",
    "week_3_dates = [\"24-05-21\", \"25-05-21\", \"26-05-21\", \"27-05-21\", \"28-05-21\", \"29-05-21\", \"30-05-21\"]\n",
    "week_4_dates = [\"31-05-21\", \"01-06-21\", \"02-06-21\", \"03-06-21\", \"04-06-21\", \"05-06-21\", \"06-06-21\"]\n",
    "week_5_dates = [\"07-06-21\", \"08-06-21\", \"09-06-21\", \"10-06-21\", \"11-06-21\", \"12-06-21\", \"13-06-21\"]\n",
    "week_6_dates = [\"14-06-21\", \"15-06-21\", \"16-06-21\", \"17-06-21\", \"18-06-21\", \"19-06-21\", \"20-06-21\"]\n",
    "\n",
    "\n",
    "dir_dataset = 'datasetMaggioSettembre/unione_channels/'\n",
    "files_dataset1 = ['ln_' + str(date) + '.json' for date in week_1_dates]\n",
    "files_dataset2 = ['ln_' + str(date) + '.json' for date in week_2_dates]\n",
    "files_dataset3 = ['ln_' + str(date) + '.json' for date in week_3_dates]\n",
    "files_dataset4 = ['ln_' + str(date) + '.json' for date in week_4_dates]\n",
    "files_dataset5 = ['ln_' + str(date) + '.json' for date in week_5_dates]\n",
    "files_dataset6 = ['ln_' + str(date) + '.json' for date in week_6_dates]\n",
    "\n",
    "\n",
    "dir_channels = 'datasetMaggioSettembre/channels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In comune tra week1 e week2: 7254\n",
      "In comune tra week1 e week3: 7228\n",
      "In comune tra week1 e week4: 7204\n",
      "In comune tra week1 e week5: 7141\n",
      "In comune tra week1 e week6: 7125\n",
      "In comune tra week2 e week3: 7228\n",
      "In comune tra week2 e week4: 7204\n",
      "In comune tra week2 e week5: 7141\n",
      "In comune tra week2 e week6: 7125\n",
      "In comune tra week3 e week4: 7204\n",
      "In comune tra week3 e week5: 7141\n",
      "In comune tra week3 e week6: 7125\n",
      "In comune tra week4 e week5: 7141\n",
      "In comune tra week4 e week6: 7125\n",
      "In comune tra week5 e week6: 7125\n",
      "Canali in comune tra week1,week2,week3,week4,week5,week6: 7125\n"
     ]
    }
   ],
   "source": [
    "with open (dir_dataset + 'week1.json') as one, open (dir_dataset + 'week2.json') as two, open (dir_dataset + 'week3.json') as three, open (dir_dataset + 'week4.json') as four, open (dir_dataset + 'week5.json') as five, open (dir_dataset + 'week6.json') as six :\n",
    "    data1 = json.load(one)\n",
    "    data2 = json.load(two)\n",
    "    data3 = json.load(three)\n",
    "    data4 = json.load(four)\n",
    "    data5 = json.load(five)\n",
    "    data6 = json.load(six)\n",
    "df1 = pd.json_normalize(data1)\n",
    "df2 = pd.json_normalize(data2)\n",
    "df3 = pd.json_normalize(data3)\n",
    "df4 = pd.json_normalize(data4)\n",
    "df5 = pd.json_normalize(data5)\n",
    "df6 = pd.json_normalize(data6)\n",
    "\n",
    "\n",
    "in_common12 = df1[df1['channel_id'].isin(df2['channel_id'])]\n",
    "in_common13 = df1[df1['channel_id'].isin(df3['channel_id'])]\n",
    "in_common14 = df1[df1['channel_id'].isin(df4['channel_id'])]\n",
    "in_common15 = df1[df1['channel_id'].isin(df5['channel_id'])]\n",
    "in_common16 = df1[df1['channel_id'].isin(df6['channel_id'])]\n",
    "in_common23 = df2[df2['channel_id'].isin(df3['channel_id'])]\n",
    "in_common24 = df2[df2['channel_id'].isin(df4['channel_id'])]\n",
    "in_common25 = df2[df2['channel_id'].isin(df5['channel_id'])]\n",
    "in_common26 = df2[df2['channel_id'].isin(df6['channel_id'])]\n",
    "in_common34 = df3[df3['channel_id'].isin(df4['channel_id'])]\n",
    "in_common35 = df3[df3['channel_id'].isin(df5['channel_id'])]\n",
    "in_common36 = df3[df3['channel_id'].isin(df6['channel_id'])]\n",
    "in_common45 = df4[df4['channel_id'].isin(df5['channel_id'])]\n",
    "in_common46 = df4[df4['channel_id'].isin(df6['channel_id'])]\n",
    "in_common56 = df5[df5['channel_id'].isin(df6['channel_id'])]\n",
    "\n",
    "    \n",
    "print(\"In comune tra week1 e week2:\" ,len(in_common12))\n",
    "print(\"In comune tra week1 e week3:\" ,len(in_common13))\n",
    "print(\"In comune tra week1 e week4:\" ,len(in_common14))\n",
    "print(\"In comune tra week1 e week5:\" ,len(in_common15))\n",
    "print(\"In comune tra week1 e week6:\" ,len(in_common16))\n",
    "\n",
    "print(\"In comune tra week2 e week3:\" ,len(in_common23))\n",
    "print(\"In comune tra week2 e week4:\" ,len(in_common24))\n",
    "print(\"In comune tra week2 e week5:\" ,len(in_common25))\n",
    "print(\"In comune tra week2 e week6:\" ,len(in_common26))\n",
    "\n",
    "print(\"In comune tra week3 e week4:\" ,len(in_common34))\n",
    "print(\"In comune tra week3 e week5:\" ,len(in_common35))\n",
    "print(\"In comune tra week3 e week6:\" ,len(in_common36))\n",
    "\n",
    "print(\"In comune tra week4 e week5:\" ,len(in_common45))\n",
    "print(\"In comune tra week4 e week6:\" ,len(in_common46))\n",
    "\n",
    "print(\"In comune tra week5 e week6:\" ,len(in_common56))\n",
    "\n",
    "in_commonall = df1[df1['channel_id'].isin(df2['channel_id']) & df1['channel_id'].isin(df3['channel_id']) & df1['channel_id'].isin(df4['channel_id']) & df1['channel_id'].isin(df5['channel_id']) & df1['channel_id'].isin(df6['channel_id'])]\n",
    "print(\"Canali in comune tra week1,week2,week3,week4,week5,week6:\" , len(in_commonall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canali in comune tra week1,week2,week3,week4,week5,week6 - dopo aver eliminato i multielementi: 6977\n",
      "\n",
      "Canali in comune tra week1,week2,week3,week4,week5,week6 CONFRONTABILI (senza campi null): 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#elimino i canali doppi : da multigrafo a grafo : ottengo 3mila canali in meno circa\n",
    "df_without_duplicates = in_commonall.drop_duplicates(subset=['node1_pub','node2_pub'])\n",
    "print(f\"Canali in comune tra week1,week2,week3,week4,week5,week6 - dopo aver eliminato i multielementi: {len(df_without_duplicates)}\\n\")\n",
    "df_without_dup_copy = df_without_duplicates.copy()\n",
    "#rimuovo le colonne policy che sono sempre null\n",
    "df_without_dup_copy = df_without_duplicates.drop(['node1_policy','node2_policy'],axis=1)\n",
    "#elimino le righe in cui almeno un elemento Ã¨ null -> df definitivo\n",
    "df_without_dup_copy.dropna( how='any',axis=0,inplace=True)\n",
    "print(f\"Canali in comune tra week1,week2,week3,week4,week5,week6 CONFRONTABILI (senza campi null): {len(df_without_dup_copy)}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90e315135b2281b752a7f250632c791a0dae1003299eabe9b8abad9d58b3e8e7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
